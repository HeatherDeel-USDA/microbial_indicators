---
title: "18S_EC"
author: "Heather Deel"
date: "2023-09-22"
output: html_document
---

### Setup and packages
```{r setup, include=FALSE}
library(tidymodels)
library(tidyverse)
library(workflows)
library(tune)
library(metagMisc)
library(ranger)
library(randomForest)
```

### Load and format data
# only need to run this once - can skip to the next chunk
# run on local computer
```{r}
# we don't need the full phyloseq from before, so reimporting
func <- read.delim('picrust2_files/18S/EC_metagenome_out/pred_metagenome_contrib.tsv.gz', sep='\t')
df <- read.delim('picrust2_files/18S/picrust2_out_SHAI_18S/marker_nsti_predicted.tsv.gz', sep = '\t')

names(df) <- c("taxon", "genome_18S_count", "metadata_NSTI")

# combine two files
func <- func %>%
  full_join(df, by="taxon")

# read in metadata
data.18S <- read.delim('metadata/SHAI.Meta.6September2023.q2.18S.txt', sep = '\t')

# get qPCR data into func
# subset data.18S to just SampleID and qPCR_18S
qPCR_18S_df <- data.18S[,c(1,3)]
colnames(qPCR_18S_df)[1] <- "sample"
func <- merge(func, qPCR_18S_df, by = "sample")
func <- func %>% 
  filter(!is.na(qPCR_18S))

# we imported un-normalized counts, so normalizing here
func$gene_counts <- func$taxon_rel_abun / 100 * func$genome_function_count / func$genome_18S_count * func$qPCR_18S

# change column name "function" to "EC"
colnames(func)[2] <- "EC"

# pool data by sample and function
otu <- func %>%
  group_by(sample, EC) %>%
  summarize(sum=sum(gene_counts))
otu <- otu %>%
  spread(key=sample, value=sum)
otu <- data.frame(otu)
otu[is.na(otu)] <- 0
row.names(otu) <- otu$EC
otu <- otu[,-1]

# transpose the "otu" table
otu <- t(otu)

# convert matrix to data frame
otu <- as.data.frame(otu)

# make the sample names a column for merging later
otu <- tibble::rownames_to_column(otu, "SampleID")

# merge metadata and "otu" table
SHAI18S_all <- merge(data.18S, otu, by = "SampleID")
SHAI18S_ml <- as.data.frame(SHAI18S_all)

saveRDS(SHAI18S_ml, "machine_learning/18S_EC/SHAI18S_ml_EC.RDS")
```

### Predict Overall CASH rating
# Run 25 times, with outputs 1-25, to account for lucky/unlucky splits after tuning
# Run locally
```{r}
SHAI18S_ml <- readRDS("machine_learning/18S_EC/SHAI18S_ml_EC.RDS")

SHAI18S_ml_CASH <- SHAI18S_ml[,c(97,154:1282)]

set.seed(1)

#for (i in 1:25) {
  soil_split <- initial_split(SHAI18S_ml_CASH, prop = 4/5)
  soil_split
  # 252 samples in training, 64 in testing, 316 total
  
  # extract the train and test sets
  soil_train <- training(soil_split)
  soil_test <- testing(soil_split)
  
  # cross validation
  soil_cv <- vfold_cv(soil_train, v = 5, repeats = 10, strata = NULL)
  
  # define a "recipe", i.e., the role of each variable in the model
  # predicting overall CASH rating, and all other variables (ECs) are predictors
  # if pre-processing steps or checks are needed (e.g., normalization), can use ?selections to see what selectors can be used
  
  soil_recipe <- recipe(Overall ~ ., data = SHAI18S_ml_CASH)
  soil_recipe
  # 1129 predictors
  
  # specify the model
  # tune randomness, number of trees, and min nodes/max depth (# of splits each decision tree can make)
  # set_args values = tune() when tuning
  # change set_args parameters to tuned grid values after tuning
  rf_model <- rand_forest() %>% 
    set_args(mtry = tune(), trees =tune(), min_n = tune()) %>%
    set_engine("ranger", importance = "impurity") %>%
    set_mode("regression")
  
  # set the workflow
  rf_workflow <- workflow() %>%
    add_recipe(soil_recipe) %>%
    add_model(rf_model)
  
  # tune the parameters
  # comment out section between ########## when not tuning
  ##########
  # doing 25%, 50%, and 75% of the total number of predictors, respectively
  rf_grid <- expand.grid(mtry = c(611,1223,1834),
                         trees = c(100,250,500),
                         min_n = c(3,5,7))
  
  # extract results
  rf_tune_results <- rf_workflow %>%
    tune_grid(resamples = soil_cv, grid = rf_grid, metrics = metric_set(mae, rmse))
  
  # save tune results
  saveRDS(rf_tune_results, "/project/soil_micro_lab/micro_indicators/machine_learning/18S_EC/CASH_model_results/SHAI18S_ml_CASH_tune_results.RDS")
  
  rf_tune_results %>%
    collect_metrics()
  
  # finalize the workflow
  param_final <- rf_tune_results %>%
    select_best(metric = "mae")
  param_final
  
  rf_workflow <- rf_workflow %>%
    finalize_workflow(param_final)
  ##########
  
  # fit the model
  # this will fit on the training set and evaluate on test set
  rf_fit <- rf_workflow %>%
    last_fit(soil_split)
  rf_fit
  
  # save the fit
  saveRDS(rf_fit, paste("/project/soil_micro_lab/micro_indicators/machine_learning/16S_EC/CASH_model_results/ml_all_EC_fit", i, ".RDS", sep = ""))
  
  # see how well the model performs
  test_performance <- rf_fit %>% collect_metrics()
  test_performance
  
  # generate predictions from the test set
  test_predictions <- rf_fit %>% collect_predictions()
  test_predictions
  
  # graph a regression of predicted vs observed SH_rating values
  CASH_EC_lm <- lm(Overall ~ .pred, data = test_predictions)
  p1 <- ggplot(CASH_EC_lm$model, aes(x = Overall, y = .pred)) +
    geom_point() +
    stat_smooth(method = "lm", se = TRUE, level = 0.95) +
    labs(title = paste("Adj R2 =",signif(summary(CASH_EC_lm)$adj.r.squared, 2),
                       " P =",signif(summary(CASH_EC_lm)$coef[2,4], 2)),
                       x = "Observed CASH Rating", y = "Predicted CASH Rating") +
    theme_bw()
  p1
  
  # save plot
  ggsave(paste("/project/soil_micro_lab/micro_indicators/machine_learning/16S_EC/CASH_model_results/ml_all_EC_pred_vs_obs", i, ".tiff", sep = ""), unit = "in", width = 6, height = 6, dpi = 300, device = "tiff")
  
  # fitting the final model
  # uses all data that can be tested on a new data set
  final_model <- fit(rf_workflow, ml_all)
  
  # save the final model
  saveRDS(final_model, paste("/project/soil_micro_lab/micro_indicators/machine_learning/16S_EC/CASH_model_results/ml_all_EC_final_model", i, ".RDS", sep = ""))
  
  # variable importance
  ranger_obj <- pull_workflow_fit(final_model)$fit
  ranger_obj
  var_importance <- as.data.frame(ranger_obj$variable.importance)
  write.csv(var_importance, paste("/project/soil_micro_lab/micro_indicators/machine_learning/16S_EC/CASH_model_results/var_importance_EC", i, ".csv", sep = ""), row.names = TRUE)
}
```



