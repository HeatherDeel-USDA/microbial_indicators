---
title: "Machine Learning Graphing"
author: "Heather Deel"
date: "2023-09-18"
output: html_document
---

### Libraries
```{r}
library(ggplot2)
library(readxl)
library(ggpubr)
library(paletteer)
library(tidyverse)
library(sjPlot)
library(cowplot)
```

### Comparison R^2 of different data types
```{r}
# tax data was pulled from dan_out/All_stats_randomForest and added to All_stats.csv
ml_stats <- read.csv("machine_learning/16S_EC/All_stats.csv")

p1 <- ggplot(ml_stats, aes(x=myVar, y=r2_val, fill = RA_total)) + 
  geom_boxplot() + 
  xlab("Indicator") +
  ylab(bquote(R^2~"Values")) +
  theme_bw() + 
  ylim(0,1) +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  scale_fill_discrete(name = "Data Type", labels = c("EC RA", "EC Total", "GIBBs RA",
                                                     "GIBBs Total", "Tax RA", "Tax Total")) +
  scale_x_discrete(labels = c("ACE","Active C","Agg. Stab.","Fe","K","Mg","Mn","P",
                              "pH","Respiration","SOM","Water Capacity","Zn"))
p1

ggsave("figures/ml_ec_r2_all.pdf", unit = "in", width = 10, height = 5, dpi = 300, device = "pdf")
ggsave("figures/ml_ec_r2_all.tiff", unit = "in", width = 10, height = 5, dpi = 300, device = "tiff")
```

### Boxplot of R^2 values for each indicator
# just relative abundance
```{r}
ml_stats_RA <- filter(ml_stats, RA_total == "EC_RA")

p1 <- ggplot(ml_stats_RA, aes(x=myVar, y=r2_val)) + 
  geom_boxplot(fill = "#F8766D") + 
  xlab("Indicator") +
  ylab(bquote(R^2~"Values")) +
  theme_bw() + 
  ylim(0,1) +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  scale_x_discrete(labels = c("ACE","Active C","Agg. Stab.","Fe","K","Mg","Mn","P",
                              "pH","Respiration","SOM","Water Capacity","Zn"))
p1

ggsave("figures/ml_ec_r2_RA.pdf", unit = "in", width = 10, height = 5, dpi = 300, device = "pdf")
ggsave("figures/ml_ec_r2_RA.tiff", unit = "in", width = 10, height = 5, dpi = 300, device = "tiff")
```

### Feature importance distributions
```{r}
gibbs <- read.csv('picrust2_files/GIBBs.EC.numbers.csv')
gibbs <- gibbs %>%
  filter(Missing != 'x')
gibbs$EC <- gsub(":","_", gibbs$EC)
gibbs$EC <- gsub("\\.","_", gibbs$EC)

myVars <- c('ace', 'SOM', 'activeC', 'resp', 'agg_stab', 'water_cap', 'ph', 'p', 'k', 'mg', 'fe', 'mn', 'zn')

# models with all enzymes
for (myVar in myVars) {
  df <- read.csv(paste0("machine_learning/16S_EC/", myVar, "_model_results_RA_corr/", myVar, "_RA_corr_varimp.csv"), header=FALSE)
  names(df) <- c('Predictor', 'VIP', 'Run')

  gDF <- df %>%
    left_join(gibbs, by=c("Predictor"="EC")) %>% 
    mutate(Short=fct_reorder(Short, VIP, .fun=mean, .desc=TRUE)) # sort levels by mean VIP

  gDF <- gDF %>% group_by(Predictor) %>% 
    mutate(Var = mean(VIP)) %>%
    filter(Var > 0.01) %>% select(-Var) %>%   # filter out poor indicators
    mutate(VIP_scaled = scale(VIP)) %>% 
    mutate(all_gibbs = "all")
  
  write.table(cbind(gDF, myVar), file = "machine_learning/16S_EC/final_varimps.csv", 
              col.names = FALSE, row.names = FALSE, append = TRUE, sep = ",")

  colors <- paletteer_d(`"ggsci::category20_d3"`)

  p <- ggplot(gDF, aes(x=Predictor, y=VIP, fill=Category)) +
    scale_fill_manual(values=colors, na.value="white") +
    geom_boxplot() + 
    theme_bw() +
    theme(axis.text.x=element_text(angle=90)) +
    labs(x="", y="Variable Importance", title = myVar)
  p
  ggsave(paste0("figures/varimps/", myVar, "_varimp.tiff"), unit = "in", width = 8, height = 6, dpi = 300, device = "tiff")
}

# models with GIBBs enzymes
for (myVar in myVars) {
  df <- read.csv(paste0("machine_learning/16S_EC/", myVar, "_model_results_RA_corr_GIBBs/", myVar, "_RA_corr_GIBBs_varimp.csv"), header=FALSE)
  names(df) <- c('Predictor', 'VIP', 'Run')

  gDF <- df %>%
    left_join(gibbs, by=c("Predictor"="EC")) %>% 
    mutate(Short=fct_reorder(Short, VIP, .fun=mean, .desc=TRUE)) # sort levels by mean VIP

  gDF <- gDF %>% group_by(Predictor) %>% 
    mutate(Var = mean(VIP)) %>%
    filter(Var > 0.01) %>% select(-Var) %>% # filter out poor indicators
    mutate(VIP_scaled = scale(VIP)) %>%  # scale VIP
    mutate(all_gibbs = "GIBBs")
  
  # write important features + myVar name to a file
  write.table(cbind(gDF, myVar), file = "machine_learning/16S_EC/final_varimps.csv", 
              col.names = FALSE, row.names = FALSE, append = TRUE, sep = ",")

  colors <- paletteer_d(`"ggsci::category20_d3"`)

  p <- ggplot(gDF, aes(x=Predictor, y=VIP, fill=Category)) +
    scale_fill_manual(values=colors, na.value="white") +
    geom_boxplot() + 
    theme_bw() +
    theme(axis.text.x=element_text(angle=90)) +
    labs(x="", y="GIBBs Variable Importance", title = myVar)
  p
  ggsave(paste0("figures/varimps/", myVar, "_varimp_GIBBs.tiff"), unit = "in", width = 8, height = 6, dpi = 300, device = "tiff")
}
```

### Make varimp list of GIBBs + important features for each indicator
```{r}
varimp_df <- read.csv("machine_learning/16S_EC/final_varimps.csv", header = FALSE)

colnames(varimp_df) <- c("Predictor","VIP","Run","Category","Class","Sub_class",
                         "Name","Short","Book","Missing","VIP_scaled","all_gibbs",
                         "indicator")

myVars <- c('ace', 'SOM', 'activeC', 'resp', 'agg_stab', 'water_cap', 'ph', 'p', 'k', 'mg', 'fe', 'mn', 'zn')

for (myVar in myVars) {
  varimp_df_filt <- filter(varimp_df, indicator == myVar)
  varimp_df_list <- varimp_df_filt %>% 
    group_by(Predictor) %>% 
    summarize(VIP_scaled_avg = mean(VIP_scaled))
  write.csv(varimp_df_list, file = paste0("machine_learning/16S_FINAL/", myVar,"_EC_GIBBs_final.csv"),
            row.names = FALSE)
}
```

### Partial dependence plots of final models
```{r}
# show response of important features to each indicator
myVars <- c('ace', 'SOM', 'activeC', 'resp', 'agg_stab', 'water_cap', 'ph', 'p', 'k', 'mg', 'fe', 'mn', 'zn')

for (myVar in myVars) {
  filenames <- list.files(paste0("machine_learning/16S_FINAL/",myVar,"_model_results/"), pattern = paste0(myVar,"_final_pd_Predictor*"), full.names = TRUE)
  predictors <- lapply(filenames, read.csv, header = FALSE)
  colnames <- c("predictor","predictor_value","indicator_response")
  predictors <- lapply(predictors, setNames, colnames)
  make_graphs <- function(x) {
    ggplot(x, aes(x = predictor_value, y = indicator_response, group = factor(predictor))) +
    geom_line() +
    theme(axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 90)) +
    facet_wrap(~predictor)
  }
  p <- lapply(predictors, make_graphs)
  p2 <- ggarrange(p[[1]],p[[2]],p[[3]],p[[4]],p[[5]],
                  p[[6]],p[[7]],p[[8]],p[[9]],p[[10]],
                  nrow = 2, ncol = 5)
  p2
  annotate_figure(p2, left = text_grob("Indicator", rot = 90),
                  bottom = text_grob("Feature Value"),
                  top = text_grob(myVar))
  ggsave(paste0("figures/pdp/", myVar, "_pdp.pdf"), unit = "in", width = 10, height = 4, dpi = 300, device = "pdf")
}

```

### Relative abundance of ECs by subclasses
```{r}

```

### PCoA of ECs
```{r}

```

