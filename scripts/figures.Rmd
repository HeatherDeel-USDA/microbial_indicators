---
title: "Machine Learning Graphing"
author: "Heather Deel"
date: "2023-09-18"
output: html_document
---

### Need to remake all figures with new model results

### Libraries
```{r}
library(ggplot2)
library(readxl)
library(ggpubr)
library(paletteer)
library(tidyverse)
library(sjPlot)
library(cowplot)
library(janitor)
library(phyloseq)
```

### Comparison R^2 of different data types
```{r}
# tax data was pulled from dan_out/All_stats_randomForest and added to All_stats.csv
ml_stats <- read.csv("machine_learning/16S_EC/All_stats.csv")

p1 <- ggplot(ml_stats, aes(x=myVar, y=r2_val, fill = RA_total_GIBBs)) + 
  geom_boxplot() + 
  xlab("Indicator") +
  ylab(bquote(R^2~"Values")) +
  theme_bw() + 
  ylim(0,1) +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  scale_fill_discrete(name = "Data Type", labels = c("EC RA", "EC Total", "GIBBs RA",
                                                     "GIBBs Total", "Tax RA", "Tax Total")) +
  scale_x_discrete(labels = c("ACE","Active C","Agg. Stab.","Fe","K","Mg","Mn","P",
                              "pH","Respiration","SOM","Water Capacity","Zn"))
p1

ggsave("figures/ml_ec_r2_all.pdf", unit = "in", width = 10, height = 5, dpi = 300, device = "pdf")
ggsave("figures/ml_ec_r2_all.tiff", unit = "in", width = 10, height = 5, dpi = 300, device = "tiff")
```

### Boxplot of R^2 values for each indicator
# just relative abundance
```{r}
ml_stats_RA <- filter(ml_stats, RA_total_GIBBs == "RA")

p1 <- ggplot(ml_stats_RA, aes(x=myVar, y=r2_val)) + 
  geom_boxplot(fill = "#F8766D") + 
  xlab("Indicator") +
  ylab(bquote(R^2~"Values")) +
  theme_bw() + 
  ylim(0,1) +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  scale_x_discrete(labels = c("ACE","Active C","Agg. Stab.","Fe","K","Mg","Mn","P",
                              "pH","Respiration","SOM","Water Capacity","Zn"))
p1

ggsave("figures/ml_ec_r2_RA.pdf", unit = "in", width = 10, height = 5, dpi = 300, device = "pdf")
ggsave("figures/ml_ec_r2_RA.tiff", unit = "in", width = 10, height = 5, dpi = 300, device = "tiff")
```

### Feature importance distributions
# don't need to filter or scale, can just select the top 20 important features
# will need to change how I import the varimps since they are now in their own file for each of the 1-25 runs

```{r}
gibbs <- read.csv('picrust2_files/GIBBs.EC.numbers.csv')
gibbs <- gibbs %>%
  filter(Missing != 'x')
gibbs$EC <- gsub(":","_", gibbs$EC)
gibbs$EC <- gsub("\\.","_", gibbs$EC)

myVars <- c('ace', 'SOM', 'activeC', 'resp', 'agg_stab', 'water_cap', 'ph', 'p', 'k', 'mg', 'fe', 'mn', 'zn')

# models with all enzymes
for (myVar in myVars) {
    filenames <- list.files(paste0("machine_learning/16S_EC/",myVar,"_model_results_RA_corr/"), pattern = paste0(myVar,"_RA_corr_varimp*"), full.names = TRUE)
  varimps <- lapply(filenames, read.csv, header = FALSE)
  varimps_full <- varimps %>% 
    reduce(full_join)

  names(varimps_full) <- c('Predictor', 'VIP', 'Run')
  varimps_full$Predictor <- gsub("EC_","EC:", varimps_full$Predictor)
  varimps_full$Predictor <- gsub("_","\\.", varimps_full$Predictor)

  gDF <- varimps_full %>%
    left_join(gibbs, by=c("Predictor"="EC")) %>% 
    mutate(Predictor=fct_reorder(Predictor, VIP, .fun=median, .desc=TRUE))

  # filter out poor indicators
  temp <- gDF %>% group_by(Predictor) %>%
    summarise(Var = median(VIP)) %>%
    top_n(20, Var) 
  
  gDF <- gDF %>%
    filter(Predictor %in% temp$Predictor)
  
  #colors <- paletteer_d(`"ggsci::category20_d3"`)
  colors <- c("Biocontrol" = "#1F77B4FF", 
              "C cycling" = "#FF7F0EFF",
              "C/N cycling" = "#2CA02CFF",
              "N cycling" = "#D62728FF", 
              "P cycling" = "#9467BDFF", 
              "S cycling" = "#8C564BFF",
              "Stess" = "#E377C2FF",
              "Siderophore" = "#7F7F7FFF",
              "Other" = "white")
  
  means <- aggregate(VIP ~ Predictor, gDF, median)
  means$Category <- 'Other'
  means$VIP <- round(means$VIP, 3)
  p <- ggplot(gDF, aes(x=Predictor, y=VIP, fill=Category)) +
    scale_fill_manual(values=colors, na.value="white") +
    geom_boxplot() + 
    geom_point(aes(fill=Category), shape=21) + 
    #stat_summary(fun=mean, colour="black", geom="point", 
    #            shape=18, size=3, show.legend=FALSE) + 
    geom_text(data = means, aes(label = VIP, y = -0.025), size=2.8, fontface='italic', angle=30) +
    theme_bw() +
    theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5)) +
    labs(x="", y="Variable Importance")
  p
    ggsave(paste0("figures/", myVar, "_RA_corr_varimp.png"), device='png', dpi=600, height=6, width=8)
  
  # before was writing to this file to use in the final models, but not sure this is what we want to do now - how do we select what features should go in the final model?
  #write.table(cbind(gDF, myVar), file = "machine_learning/16S_EC/final_varimps.csv", 
  #            col.names = FALSE, row.names = FALSE, append = TRUE, sep = ",")
}

# models with GIBBs enzymes
for (myVar in myVars) {
     filenames <- list.files(paste0("machine_learning/16S_EC/",myVar,"_model_results_RA_corr_GIBBs/"), pattern = paste0(myVar,"_RA_corr_GIBBs_varimp*"), full.names = TRUE)
  varimps <- lapply(filenames, read.csv, header = FALSE)
  varimps_full <- varimps %>% 
    reduce(full_join)

  names(varimps_full) <- c('Predictor', 'VIP', 'Run')
  varimps_full$Predictor <- gsub("EC_","EC:", varimps_full$Predictor)
  varimps_full$Predictor <- gsub("_","\\.", varimps_full$Predictor)

  gDF <- varimps_full %>%
    left_join(gibbs, by=c("Predictor"="EC")) %>% 
    mutate(Predictor=fct_reorder(Predictor, VIP, .fun=median, .desc=TRUE))

  # filter out poor indicators
  temp <- gDF %>% group_by(Predictor) %>%
    summarise(Var = median(VIP)) %>%
    top_n(20, Var) 
  
  gDF <- gDF %>%
    filter(Predictor %in% temp$Predictor)
  
  #colors <- paletteer_d(`"ggsci::category20_d3"`)
  colors <- c("Biocontrol" = "#1F77B4FF", 
              "C cycling" = "#FF7F0EFF",
              "C/N cycling" = "#2CA02CFF",
              "N cycling" = "#D62728FF", 
              "P cycling" = "#9467BDFF", 
              "S cycling" = "#8C564BFF",
              "Stess" = "#E377C2FF",
              "Siderophore" = "#7F7F7FFF",
              "Other" = "white")
  
  means <- aggregate(VIP ~ Predictor, gDF, median)
  means$Category <- 'Other'
  means$VIP <- round(means$VIP, 3)
  p <- ggplot(gDF, aes(x=Predictor, y=VIP, fill=Category)) +
    scale_fill_manual(values=colors, na.value="white") +
    geom_boxplot() + 
    geom_point(aes(fill=Category), shape=21) + 
    #stat_summary(fun=mean, colour="black", geom="point", 
    #            shape=18, size=3, show.legend=FALSE) + 
    geom_text(data = means, aes(label = VIP, y = -0.025), size=2.8, fontface='italic', angle=30) +
    theme_bw() +
    theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5)) +
    labs(x="", y="Variable Importance")
  p
    ggsave(paste0("figures/", myVar, "_RA_corr_GIBBs_varimp.png"), device='png', dpi=600, height=6, width=8)
  
  # before was writing to this file to use in the final models, but not sure this is what we want to do now - how do we select what features should go in the final model?
  #write.table(cbind(gDF, myVar), file = "machine_learning/16S_EC/final_varimps_GIBBs.csv", 
  #            col.names = FALSE, row.names = FALSE, append = TRUE, sep = ",")
}
```

### Make varimp list of GIBBs + important features for each indicator
####### can probably erase this after I run the final models - should be there and not here
```{r}
varimp_df <- read.csv("machine_learning/16S_EC/final_varimps.csv", header = FALSE)

colnames(varimp_df) <- c("Predictor","VIP","Run","Category","Class","Sub_class",
                         "Name","Short","Book","Missing","VIP_scaled","all_gibbs",
                         "indicator")

myVars <- c('ace', 'SOM', 'activeC', 'resp', 'agg_stab', 'water_cap', 'ph', 'p', 'k', 'mg', 'fe', 'mn', 'zn')

for (myVar in myVars) {
  varimp_df_filt <- filter(varimp_df, indicator == myVar)
  varimp_df_list <- varimp_df_filt %>% 
    group_by(Predictor) %>% 
    summarize(VIP_scaled_avg = mean(VIP_scaled))
  write.csv(varimp_df_list, file = paste0("machine_learning/16S_FINAL/", myVar,"_EC_GIBBs_final.csv"),
            row.names = FALSE)
}
```

### Partial dependence plots of final models
### To do:
# rerun these with new model results
# haven't yet rerun final models because we may be reducing colinear features
# I also need to unscale clay when it is included
```{r}
# show response of important features to each indicator
# the nutrients aren't scaled, so process those in a separate loop
myVars1 <- c('ace', 'SOM', 'activeC', 'resp', 'agg_stab', 'water_cap')

myVar <- 'agg_stab'

# read in data.pred so I can use the attributes to unscale the indicators
data.pred <- readRDS("metadata/data.pred.SHMI.RDS")

for (myVar in myVars1) {
  # read in and format files
  filenames <- list.files(paste0("machine_learning/16S_FINAL/",myVar,"_model_results/"), pattern = paste0(myVar,"_final_pd_Predictor*"), full.names = TRUE)
  predictors <- lapply(filenames, read.csv, header = FALSE)
  colnames <- c("predictor","predictor_value","indicator_response")
  predictors <- lapply(predictors, setNames, colnames)
  
  # create df with scaling attributes
  scale_attr <- data.frame(attributes(data.pred[[myVar]]))
  scaled_scale <- scale_attr$scaled.scale[1]
  scaled_center <- scale_attr$scaled.center[1]
  
  # unscale
  for (i in seq_along(predictors)) {
    predictors[[i]]$unscaled <- (predictors[[i]]$indicator_response * scaled_scale) + scaled_center
  }
  
  # create functions for making pdps and bar charts
  make_graphs <- function(x) {
    ggplot(x, aes(x = predictor_value, y = unscaled, group = factor(predictor))) +
    geom_line() +
    theme(axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 90)) +
    facet_wrap(~predictor)
  }
  make_bargraphs <- function(x) {
    ggplot(x, aes(x = predictor_value, y = unscaled, group = factor(predictor))) +
    geom_bar(stat = 'identity') +
    theme(axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 90)) +
      facet_wrap(~predictor)
  }
  
  # make pdps and climate bar charts
  for (i in seq_along(predictors)) {
    if (predictors[[i]]$predictor[1] == "ClimateZ") { 
      p1 = make_bargraphs(predictors[[i]])
    }
    if (predictors[[i]]$predictor[1] != "ClimateZ") { 
      predictors_EC <- lapply(predictors, function(x) filter(x, predictor != "ClimateZ"))
      predictors_EC <- predictors_EC[sapply(predictors_EC, function(x) dim(x)[1]) > 0]
      
      p2 = lapply(predictors_EC, make_graphs)
    }
  }
  
  # merge graphs and save
  p3 <- ggarrange(p1,p2[[1]],p2[[2]],p2[[3]],p2[[4]], 
                  p2[[5]],p2[[6]],p2[[7]],p2[[8]],p2[[9]],
                  nrow = 2, ncol = 5)
  p3
  annotate_figure(p3, left = text_grob(myVar, rot = 90),
                  bottom = text_grob("Feature Value"))
  ggsave(paste0("figures/pdp/", myVar, "_pdp.png"), unit = "in", width = 10, height = 4, dpi = 300, device = "png")
}

myVars2 <- c('p', 'k', 'mg', 'fe', 'mn', 'zn','ph')

# read in ml_EC_RA_corr so I can use the attributes to unscale the nutrients and ph
ml_EC_16S <- readRDS("machine_learning/EC_RA_corr/ml_EC_RA_corr.RDS")

# create df with scaling attributes for each indicator
scale_attr <- data.frame(attributes(ml_EC_16S[[myVars2]]))
scaled_scale <- scale_attr$scaled.scale[1]
scaled_center <- scale_attr$scaled.center[1]

for (myVar in myVars1) {
  filenames <- list.files(paste0("machine_learning/16S_FINAL/",myVar,"_model_results/"), pattern = paste0(myVar,"_final_pd_Predictor*"), full.names = TRUE)
  predictors <- lapply(filenames, read.csv, header = FALSE)
  colnames <- c("predictor","predictor_value","indicator_response")
  predictors <- lapply(predictors, setNames, colnames)
  for (i in seq_along(predictors)) {
    predictors[[i]]$unscaled <- predictors[[i]]$indicator_response * scaled_scale + scaled_center
  }
  make_graphs <- function(x) {
    ggplot(x, aes(x = predictor_value, y = unscaled, group = factor(predictor))) +
    geom_line() +
    theme(axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 90)) +
    facet_wrap(~predictor)
  }
  make_bargraphs <- function(x) {
    ggplot(x, aes(x = predictor_value, y = unscaled, group = factor(predictor))) +
    geom_bar(stat = 'identity') +
    theme(axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 90)) +
      facet_wrap(~predictor)
  }
  for (i in seq_along(predictors)) {
    if (predictors[[i]]$predictor[1] == "ClimateZ") { 
      p1 = make_bargraphs(predictors[[i]])
    }
    if (predictors[[i]]$predictor[1] != "ClimateZ") { 
      predictors_EC <- lapply(predictors, function(x) filter(x, predictor != "ClimateZ"))
      predictors_EC <- predictors_EC[sapply(predictors_EC, function(x) dim(x)[1]) > 0]
      
      p2 = lapply(predictors_EC, make_graphs)
    }
  }
  p3 <- ggarrange(p1,p2[[1]],p2[[2]],p2[[3]],p2[[4]], 
                  p2[[5]],p2[[6]],p2[[7]],p2[[8]],p2[[9]],
                  nrow = 2, ncol = 5)
  p3
  annotate_figure(p3, left = text_grob(myVar, rot = 90),
                  bottom = text_grob("Feature Value"))
  ggsave(paste0("figures/pdp/", myVar, "_pdp.png"), unit = "in", width = 10, height = 4, dpi = 300, device = "png")
}

  
# might need to standardize the y axis limits at some point but this is good enough for now
```

### Relative abundance of ECs by subclasses
# redo part of this section using the R way to collapse into sublevels and subsublevels - more reproducible
```{r}
ECs <- read.csv("machine_learning/EC_RA_corr/ml_EC_RA_corr.csv", check.names = FALSE)

ECs2 <- ECs[,4:2439]
ECs2_t <- t(ECs2)
ECs2_t <- data.frame(ECs2_t)
ECs2_t <- rownames_to_column(ECs2_t, var = "ECs")

# make a vector of names
EC_names <- names(ECs2)

# create list of subclasses
new <- unique(vapply(strsplit(EC_names, '\\.'), function(x) 
            paste(x[1:2], collapse='.'), character(1L)))
new <- paste0(new, ".") # adds a period at the end - needed for filtering the original df

# collapse EC list to subclasses

# one try here - not quite working
for (i in new){
  if (i %in% ECs2_t$ECs) {
    ECs2_sc <- replace(ECs2_t$ECs)
  }
}

# another try using gsub
ECs2_sc <- gsub(new, ECs2_t$ECs, ECs2_t)




# format "otu" table for importing into phyloseq
EC_subclass_t <- t(EC_subclass) %>% 
  row_to_names(row_number = 1)
EC_subclass_t <- as.matrix(EC_subclass_t)
EC_subclass_otu <- EC_subclass_t[63:123,]
EC_subclass_otu <- data.frame(EC_subclass_otu)

EC_subclass_otu_num <- lapply(EC_subclass_otu, as.numeric)
EC_subclass_otu_num <- data.frame(EC_subclass_otu_num)
rownames(EC_subclass_otu_num) <- rownames(EC_subclass_otu)

OTU = otu_table(EC_subclass_otu_num, taxa_are_rows = TRUE)

# format sample data for importing into phyloseq
EC_subclass_sam <- EC_subclass[,c(1:63,125:212)]
EC_subclass_sam <- column_to_rownames(EC_subclass_sam, var = "SampleID")
EC_subclass_sam$SHMI2_bin <- factor(EC_subclass_sam$SHMI2_bin, levels = c("very low","low","medium","high","very high"))
EC_subclass_sam$SH_bin <- factor(EC_subclass_sam$SH_bin, levels = c("very low","low","medium","high","very high"))

SAM <- sample_data(EC_subclass_sam)

# use the EC description as "taxa"
EC_desc <- read_xlsx("ec_files_expasy/enzclass_R.xlsx")
EC_desc <- column_to_rownames(EC_desc, var = "EC")
EC_desc <- as.matrix(EC_desc)
TAX <- tax_table(EC_desc)

# create phyloseq object
p_subclass <- phyloseq(OTU, TAX, SAM)

# make SHMI bar charts
plot_bar(p_subclass, x = "SHMI2_bin", fill = "Order") + 
  geom_bar(stat = "identity") +
  theme_classic() +
  labs(x = "SHMI Bin") +
  scale_fill_discrete(name = "Subclass")
ggsave("figures/EC_abund_SHMI_subclass.pdf", unit = "in", width = 6, height = 4, dpi = 300, device = "pdf")

# make SEMWISE bar charts
plot_bar(p_subclass, x = "SH_bin", fill = "Order") + # subclass
  geom_bar(stat = "identity") +
  theme_classic() +
  labs(x = "SEMWISE Bin") +
  scale_fill_discrete(name = "Subclass")
ggsave("figures/EC_abund_SEMWISE_subclass.pdf", unit = "in", width = 6, height = 4, dpi = 300, device = "pdf")

### subsubclass level data
# start from level 4 EC data and collapse to the subsubclass level in R
ECs <- read.csv("machine_learning/EC_RA_corr/ml_EC_RA_corr.csv", check.names = FALSE)

EC_subsubclass_list <- c("EC:1.1.1","EC:1.1.2","EC:1.1.3","EC:1.1.5","EC:1.1.9","EC:1.1.98","EC:1.1.99",
"EC:1.10.2","EC:1.10.3","EC:1.10.9","EC:1.11.1","EC:1.11.2","EC:1.12.1","EC:1.12.2",
"EC:1.12.5","EC:1.12.7","EC:1.12.98","EC:1.12.99","EC:1.13.11","EC:1.13.12","EC:1.13.99",
"EC:1.14.11","EC:1.14.12","EC:1.14.13","EC:1.14.14","EC:1.14.15","EC:1.14.16",
"EC:1.14.17","EC:1.14.18","EC:1.14.19","EC:1.14.21","EC:1.14.99","EC:1.15.1",
"EC:1.16.1","EC:1.16.3","EC:1.16.8","EC:1.17.1","EC:1.17.2","EC:1.17.3","EC:1.17.4",
"EC:1.17.5","EC:1.17.7","EC:1.17.99","EC:1.18.1","EC:1.18.6","EC:1.2.1","EC:1.2.3",
"EC:1.2.4","EC:1.2.5","EC:1.2.7","EC:1.2.98","EC:1.2.99","EC:1.20.1","EC:1.20.4",
"EC:1.20.9","EC:1.21.4","EC:1.21.98","EC:1.3.1","EC:1.3.3","EC:1.3.4","EC:1.3.5",
"EC:1.3.7","EC:1.3.8","EC:1.3.98","EC:1.3.99","EC:1.4.1","EC:1.4.3","EC:1.4.4",
"EC:1.4.7","EC:1.4.9","EC:1.4.99","EC:1.5.1","EC:1.5.3","EC:1.5.5","EC:1.5.8",
"EC:1.5.98","EC:1.5.99","EC:1.6.1","EC:1.6.2","EC:1.6.3","EC:1.6.5","EC:1.6.99",
"EC:1.7.1","EC:1.7.2","EC:1.7.3","EC:1.7.7","EC:1.7.99","EC:1.8.1","EC:1.8.2",
"EC:1.8.3","EC:1.8.4","EC:1.8.5","EC:1.8.7","EC:1.8.98","EC:1.8.99","EC:1.9.3",
"EC:1.97.1","EC:2.1.1","EC:2.1.2","EC:2.1.3","EC:2.1.4","EC:2.10.1","EC:2.2.1",
"EC:2.3.1","EC:2.3.2","EC:2.3.3","EC:2.4.1","EC:2.4.2","EC:2.4.99","EC:2.5.1",
"EC:2.6.1","EC:2.6.99","EC:2.7.1","EC:2.7.10","EC:2.7.11","EC:2.7.14","EC:2.7.2",
"EC:2.7.3","EC:2.7.4","EC:2.7.6","EC:2.7.7","EC:2.7.8","EC:2.7.9","EC:2.8.1",
"EC:2.8.2","EC:2.8.3","EC:2.8.4","EC:2.9.1","EC:3.1.1","EC:3.1.11","EC:3.1.12",
"EC:3.1.13","EC:3.1.2","EC:3.1.21","EC:3.1.22","EC:3.1.25","EC:3.1.26","EC:3.1.27",
"EC:3.1.3","EC:3.1.30","EC:3.1.31","EC:3.1.4","EC:3.1.5","EC:3.1.6","EC:3.1.7",
"EC:3.1.8","EC:3.10.1","EC:3.11.1","EC:3.13.1","EC:3.2.1","EC:3.2.2","EC:3.3.1",
"EC:3.3.2","EC:3.4.11","EC:3.4.13","EC:3.4.14","EC:3.4.15","EC:3.4.16","EC:3.4.17",
"EC:3.4.19","EC:3.4.21","EC:3.4.22","EC:3.4.23","EC:3.4.24","EC:3.4.25","EC:3.5.1",
"EC:3.5.2","EC:3.5.3","EC:3.5.4","EC:3.5.5","EC:3.5.99","EC:3.6.1","EC:3.6.3",
"EC:3.6.4","EC:3.7.1","EC:3.8.1","EC:4.1.1","EC:4.1.2","EC:4.1.3","EC:4.1.99",
"EC:4.2.1","EC:4.2.2","EC:4.2.3","EC:4.2.99","EC:4.3.1","EC:4.3.2","EC:4.3.3",
"EC:4.3.99","EC:4.4.1","EC:4.6.1","EC:4.7.1","EC:4.99.1","EC:5.1.1","EC:5.1.2",
"EC:5.1.3","EC:5.1.99","EC:5.2.1","EC:5.3.1","EC:5.3.2","EC:5.3.3","EC:5.3.4",
"EC:5.3.99","EC:5.4.1","EC:5.4.2","EC:5.4.3","EC:5.4.4","EC:5.4.99","EC:5.5.1",
"EC:5.99.1","EC:6.1.1","EC:6.1.2","EC:6.2.1","EC:6.3.1","EC:6.3.2","EC:6.3.3",
"EC:6.3.4","EC:6.3.5","EC:6.4.1","EC:6.5.1","EC:6.6.1")

EC_subsubclass_list2 <- paste0(EC_subsubclass_list,".")

for (i in EC_subsubclass_list2) {
  name <- paste0("Sum.", substr(i, 1, nchar(i)-1))
  temp <- ECs %>%
    select(starts_with(i)) %>%
    mutate(!!name := rowSums(., na.rm=T)) %>%
    select(!starts_with(i))
  ECs[,name] <- as.vector(temp)
}

# format "otu" table for importing into phyloseq
EC_subsubclass_t <- t(ECs) %>% 
  row_to_names(row_number = 1)
EC_subsubclass_t <- as.matrix(EC_subsubclass_t)
EC_subsubclass_otu <- EC_subsubclass_t[2588:2807,]

# get EC names to match formatting of "tax" table
x <- row.names(EC_subsubclass_otu)
rownames(EC_subsubclass_otu) <- substring(x, 5)

EC_subsubclass_otu <- data.frame(EC_subsubclass_otu)
EC_subsubclass_otu_num <- lapply(EC_subsubclass_otu, as.numeric)
EC_subsubclass_otu_num <- data.frame(EC_subsubclass_otu_num)
rownames(EC_subsubclass_otu_num) <- rownames(EC_subsubclass_otu)

# replace colon with . so it matches taxa names in "tax" table
row.names(EC_subsubclass_otu_num) <- sub(':', '\\.', row.names(EC_subsubclass_otu_num))

sample_names <- ECs$SampleID
colnames(EC_subsubclass_otu_num) <- sample_names

OTU = otu_table(EC_subsubclass_otu_num, taxa_are_rows = TRUE)

# format sample data for importing into phyloseq
EC_sam <- ECs[,c(2:3,2440:2588)]
EC_sam <- column_to_rownames(EC_sam, var = "SampleID")
EC_sam$SHMI2_bin <- factor(EC_sam$SHMI2_bin, levels = c("very low","low","medium","high","very high"))
EC_sam$SH_bin <- factor(EC_sam$SH_bin, levels = c("very low","low","medium","high","very high"))

SAM <- sample_data(EC_sam)

# use the EC description as "taxa"
EC_desc <- read_xlsx("ec_files_expasy/enzclass_R.xlsx")
EC_desc <- column_to_rownames(EC_desc, var = "EC")
EC_desc <- as.matrix(EC_desc)
EC_desc <- EC_desc[,1:3]
TAX <- tax_table(EC_desc)

# create phyloseq object
p_subsubclass <- phyloseq(OTU, TAX, SAM)

# bar chart
p_df <- psmelt(p_subsubclass)

# this works for genus and family level
ggplot(p_df, aes(x = SHMI2_bin, y = Abundance, fill = Family)) +
  geom_bar(stat = "summary", fun = "mean") +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "SHMI Bin") +
  scale_fill_discrete(name = "Sub-subclass")
ggsave("figures/EC_abund_SHMI_subsubclass.pdf", unit = "in", width = 6, height = 4, dpi = 300, device = "pdf")

ggplot(p_df, aes(x = SH_bin, y = Abundance, fill = Family)) +
  geom_bar(stat = "summary", fun = "mean") +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "SEMWISE Bin") +
  scale_fill_discrete(name = "Sub-subclass")
ggsave("figures/EC_abund_SEMWISE_subsubclass.pdf", unit = "in", width = 6, height = 4, dpi = 300, device = "pdf")

```

### PCOA at subsubclass level just to see what it looks like
# redo these using tsne
```{r}
p_ord <- ordinate(p_subsubclass, "CCA", "morisita")
plot_ordination(p_subsubclass, p_ord, "samples", color = "Previous_Crop")

# in .dkm3 script, at line 903 there is better pcoa code - tsne
```

### quick plot of climate by activeC
# and do a feature
```{r}
p <- ggplot(ml_EC_16S, aes(x = ClimateZ, y = activeC, fill = ClimateZ)) +
  geom_boxplot()
p

p <- ggplot(ml_EC_16S, aes(x = clay, y = activeC)) +
  geom_point() +
  geom_smooth()
p

p <- ggplot(ml_EC_16S, aes(x = `EC:1.10.9.1`, y = activeC)) +
  geom_point() +
  geom_smooth()
p

p <- ggplot(ml_EC_16S, aes(x = `EC:1.3.99.35`, y = activeC)) +
  geom_point() +
  geom_smooth()
p

p <- ggplot(ml_EC_16S, aes(x = `EC:3.1.1.81`, y = activeC)) +
  geom_point() +
  geom_smooth()
p

```





















