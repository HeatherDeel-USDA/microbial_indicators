---
title: "Untitled"
output: html_document
date: "2023-11-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r cars}
# libraries
library(dplyr)
library(party)
library(tidyverse)
library(Boruta)
library(moreparty)
library(permimp)
library(randomForest)

myVars <- c('ace', 'SOM', 'activeC', 'resp', 'agg_stab', 'water_cap', 'ph', 'p', 'k', 'mg', 'fe', 'mn', 'zn', 'SH_rating', 'Overall')
#myVars <- 'ace'

myDatas <- c('TAX_RA', 'TAX_Total', 'EC_RA', 'EC_RA_corr', 'EC_Total_corr')
#myDatas <- 'EC_Total_corr'

for (myVar in myVars) {
  print(paste0("Variable: ", myVar))
  
  for (myData in myDatas) {

    ml_EC_16S <- readRDS(paste0('../../machine_learning/', myData, '/ml_', myData, '.RDS'))
  
    if (myData %in% c("TAX_RA", "TAX_Total")) {
      data <- ml_EC_16S[,c(152:ncol(ml_EC_16S))]
      df.myVar <- as.vector(ml_EC_16S[,myVar])
      df.climate <- as.vector(ml_EC_16S[,'ClimateZ'])
      df.clay <- as.vector(ml_EC_16S[,'clay'])
      data <- cbind(df.myVar, df.climate, df.clay, data)
      names(data)[1] <- myVar
      names(data)[2] <- 'ClimateZ'
      names(data)[3] <- 'clay'
    } else {
      data <- ml_EC_16S %>%
        select(grep("EC:", colnames(ml_EC_16S)), ClimateZ, clay, myVar)
    }
    
    # format so : and . are replaced by _ (for varimp)
    names(data) <- gsub(":","_", names(data))
    names(data) <- gsub("\\.","_", names(data))
  
    myFormula <- as.formula(paste0(myVar, ' ~ .'))
    Boruta.res <- Boruta(myFormula, data=data, getImp=getImpRfZ)
    myFormula <- getConfirmedFormula(Boruta.res)
    keep_X <- names(Boruta.res$finalDecision[Boruta.res$finalDecision == "Confirmed"])
    print(paste0("Number of selected predictors: ", length(keep_X)))
    
    final <- data %>%
      select(all_of(keep_X), myVar)
    
    if ('ClimateZ' %in% keep_X) {
      final$ClimateZ <- factor(final$ClimateZ)
    }
  
    for (myRun in seq(1,25,1)) {
      print(paste0("Starting run: ", myRun))
      
      # split into train and test (4/5 proportion)
      final$id <- 1:nrow(final)
      train <- final %>% dplyr::sample_frac(0.80)
      test <- dplyr::anti_join(final, train, by = 'id')
      
      # get rid of id columns
      train <- train %>% select(-id)
      test <- test %>% select(-id)
      
      # randomForest on training data
      cf.train <- randomForest::randomForest(myFormula, data=train, 
                               mtry=floor(length(keep_X)/3),
                               importance=TRUE, na.action=na.omit,
                               keep.forest=TRUE, keep.inbag=TRUE)
      
      
      cf.pred <- predict(cf.train, newdata = test, OOB = TRUE, type = "response")
      
      # observed vs predicted
      cf.pred <- data.frame(cf.pred)
      colnames(cf.pred)[1] <- "pred"
      cf.pred <- rownames_to_column(cf.pred, var = "id")
      obs <- data.frame(test[,myVar])
      colnames(obs)[1] <- "obs"
      cf.pvso <- cbind(cf.pred, obs)
  
      # save R^2 and p-values to a file
      res.lm <- lm(obs ~ pred, data = cf.pvso)
      r2_val <- summary(res.lm)$adj.r.squared
      p_val <- summary(res.lm)$coef[2,4]
      
      write.table(cbind(myRun, r2_val, p_val), 
                  file = paste0("../../dan_out/", myVar, "_", myData, "_stats.csv"), 
                  col.names = FALSE,
                  append = TRUE, sep = ",", row.names = FALSE)
      
      # # # variable importances
      # imp <- permimp::permimp(cf.train, conditional=FALSE,
      #                         progressBar = TRUE, do_check=FALSE)
      #  
      # imp <- as.data.frame(imp$values)
      # names(imp) <- 'vimp'
      # imp <- imp %>% arrange(desc(vimp))
      # imp <- tibble::rownames_to_column(imp, "EC")
      # imp$Run <- myRun
      #  
      # write.table(imp, 
      #            file = paste0("../../dan_out/", myVar, "_", myData, "_varimp.csv"),
      #            col.names=FALSE,
      #            append = TRUE, sep = ",", row.names = FALSE)
      #  
      # for (EC in seq(1,10,1)) {
      #   print(paste0("Partial dependence for predictor ", EC, ": ", imp$EC[EC]))
      #   
      #   pd <- partialPlot(cf.train, train, imp$EC[EC], plot=FALSE)
      #   pd <- as.data.frame(pd)
      #   
      #   pd$EC <- imp$EC[EC]
      #   pd$run <- myRun
      #   
      #   write.table(pd, 
      #      file = paste0("../../dan_out/pdp/", myVar, "_", myData, "_Predictor.", imp$EC[EC], "_pd.csv"),
      #      col.names=FALSE,
      #      append = TRUE, sep = ",", row.names = FALSE)
      # }
    }
  }
}










# libraries
library(dplyr)
library(party)
library(tidyverse)
library(Boruta)
library(moreparty)
library(permimp)


#data <- readRDS(paste0('../../machine_learning/EC_RA_corr/ml_EC_RA_corr.RDS'))
#final <- data %>% select(!(grep("EC:", colnames(ml_EC_16S))))

data <- readRDS(paste0('../../metadata/data.pred.SHMI.RDS'))
final <- data %>%
  #select(SH, SH_rating, ace.corr, SOM.corr, activeC.corr, agg_stab.corr, resp.corr, qPCR.corr, water_cap.corr)
  select(SH, SH_rating, ace.resid, SOM.resid, activeC.resid, agg_stab.resid, resp.resid, qPCR.resid, water_cap.resid)

names(final) <- c('SH', 'SH_rating', 'ace', 'SOM', 'activeC', 'agg_stab', 'resp', 'qPCR', 'water_cap')

for (myRun in seq(1,25,1)) {
  print(paste0("Starting run: ", myRun))
  
  # split into train and test (4/5 proportion)
  final$id <- 1:nrow(final)
  train <- final %>% dplyr::sample_frac(0.80)
  test <- dplyr::anti_join(final, train, by = 'id')
  
  # get rid of id columns
  train <- train %>% select(-id)
  test <- test %>% select(-id)
  
  # cforest on training data
  my_cforest_control <- cforest_control(teststat = "quad",
      testtype = "Univ", mincriterion = 0, ntree = 500, 
      mtry = 3,
      replace = FALSE)
  
  cf.train <- cforest(SH ~ ace + SOM + activeC + agg_stab + resp + qPCR + water_cap, data = train,
                    controls = my_cforest_control)

  cf.pred <- predict(cf.train, newdata = test, OOB = TRUE, type = "response")
  
  # observed vs predicted
  colnames(cf.pred)[1] <- "pred"
  cf.pred <- data.frame(cf.pred)
  cf.pred <- rownames_to_column(cf.pred, var = "id")
  obs <- data.frame(test[,'SH'])
  colnames(obs)[1] <- "obs"
  cf.pvso <- cbind(cf.pred, obs)

  # save R^2 and p-values to a file
  res.lm <- lm(obs ~ pred, data = cf.pvso)
  r2_val <- summary(res.lm)$adj.r.squared
  p_val <- summary(res.lm)$coef[2,4]
  
  write.table(cbind(myRun, r2_val, p_val), 
              file = paste0("../../dan_out/", "SH_test", "_", myData, "_stats.csv"), 
              col.names = FALSE,
              append = TRUE, sep = ",", row.names = FALSE)
  
  # # variable importances
  # imp <- permimp::permimp(cf.train, nperm=1, OOB=TRUE, scaled=FALSE,
  #                         conditional=FALSE, threshold=0.2, asParty=FALSE,
  #                         thresholdDiagnostics = FALSE, progressBar = TRUE)
  # 
  # imp <- as.data.frame(imp$values)
  # names(imp) <- 'vimp'
  # imp <- imp %>% arrange(desc(vimp))
  # imp <- tibble::rownames_to_column(imp, "EC")
  # imp$Run <- myRun
  # 
  # write.table(imp,
  #            file = paste0("../../dan_out/", myVar, "_", myData, "_varimp.csv"),
  #            col.names=FALSE,
  #            append = TRUE, sep = ",", row.names = FALSE)
  # 
  # for (EC in seq(1,10,1)) {
  #   print(paste0("Partial dependence for predictor ", EC, ": ", imp$EC[EC]))
  # 
  #   pd <- GetPartialData(cf.train, xnames=imp$EC[EC],
  #                        quantiles=FALSE, grid.resolution = 51,
  #                        parallel=TRUE)
  #   pd$run <- myRun
  # 
  #   write.table(pd,
  #      file = paste0("../../dan_out/pdp/", myVar, "_", myData, "_Predictor.", imp$EC[EC], "_pd.csv"),
  #      col.names=FALSE,
  #      append = TRUE, sep = ",", row.names = FALSE)
  # }
}

```
