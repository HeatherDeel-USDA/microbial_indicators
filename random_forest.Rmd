---
title: "Random Forest"
author: "Heather Deel"
date: "2023-08-07"
output: html_document
---

#### models to run for now (on EC data):
# CASH overall rating + clay and climate
# SOM + clay and climate (don't think I need SOM without clay and climate)

### Setup and packages
```{r setup, include=FALSE}
library(tidymodels)
library(tidyverse)
library(workflows)
library(tune)
library(metagMisc)
library(ranger)
library(randomForest)
```

### Load and format data
# only need to run this once - can skip to the next chunk
# Run in local R
```{r}
### Hops.2018
# we don't need the full phyloseq from before, so reimporting
func <- read.delim('../picrust2_files/Hops.2018/EC/pred_metagenome_contrib.tsv.gz', sep='\t')
df <- read.delim('../picrust2_files/Hops.2018/marker_predicted_and_nsti.tsv.gz', sep = '\t')

names(df) <- c("taxon", "genome_16S_count", "metadata_NSTI")

# combine two files
func <- func %>%
  full_join(df, by="taxon")

# get other metadata
data.pred.SHMI <- readRDS('metadata/data.pred.SHMI.RDS')

# read in metadata that includes sampleIDs to merge with data.pred.SHMI
data.sampleID <- read.delim('metadata/SHAI.Meta.22March2023.q2.reduced.txt', sep = '\t')

# merge metadata files
data.merged <- merge(data.pred.SHMI, data.sampleID, by = "PLFA_ID", all.x = TRUE)

# move the sample ID column to the front
data.merged <- data.merged %>% 
  relocate(SampleID)

# get qPCR data into func
qPCR_data <- data.merged[,c(1,99)]
colnames(qPCR_data)[1] <- "sample"
func <- merge(func, qPCR_data, by = "sample")

# we imported un-normalized counts, so normalizing here
func$gene_counts <- func$taxon_rel_abun / 100 * func$genome_function_count / func$genome_16S_count * func$qPCR

# change column name "function" to "EC"
colnames(func)[2] <- "EC"

# pool data by sample and function
otu <- func %>%
  group_by(sample, EC) %>%
  summarize(sum=sum(gene_counts))
otu <- otu %>%
  spread(key=sample, value=sum)
otu <- data.frame(otu)
otu[is.na(otu)] <- 0
row.names(otu) <- otu$EC
otu <- otu[,-1]

# transpose the "otu" table
otu <- t(otu)

# convert matrix to data frame
otu <- as.data.frame(otu)

# make the sample names a column for merging later
otu <- tibble::rownames_to_column(otu, "SampleID")

# merge metadata and "otu" table
hops2018_all <- merge(data.merged, otu, by = "SampleID")
hops2018_all <- as.data.frame(hops2018_all)

# select columns to be used in ml - SampleID, ECs, and "Overall" CASH rating
hops2018_ml <- hops2018_all[,c(1,95,152:2390)]

saveRDS(hops2018_ml, "machine_learning/hops2018_ml_EC.RDS")

### Hops.ARS
# we don't need the full phyloseq from before, so reimporting
func <- read.delim('../picrust2_files/Hops.ARS/EC/pred_metagenome_contrib.tsv.gz', sep='\t')
df <- read.delim('../picrust2_files/Hops.ARS/marker_predicted_and_nsti.tsv.gz', sep = '\t')

names(df) <- c("taxon", "genome_16S_count", "metadata_NSTI")

# combine two files
func <- func %>%
  full_join(df, by="taxon")

# add qPCR data to new func object
func <- merge(func, qPCR_data, by = "sample")

# we imported un-normalized counts, so normalizing here
func$gene_counts <- func$taxon_rel_abun / 100 * func$genome_function_count / func$genome_16S_count * func$qPCR

# change column name "function" to "EC"
colnames(func)[2] <- "EC"

# pool data by sample and function
otu <- func %>%
  group_by(sample, EC) %>%
  summarize(sum=sum(gene_counts))
otu <- otu %>%
  spread(key=sample, value=sum)
otu <- data.frame(otu)
otu[is.na(otu)] <- 0
row.names(otu) <- otu$EC
otu <- otu[,-1]

# transpose the "otu" table
otu <- t(otu)

# convert matrix to data frame
otu <- as.data.frame(otu)

# make the sample names a column for merging later
otu <- tibble::rownames_to_column(otu, "SampleID")

# merge metadata and "otu" table
hopsARS_all <- merge(data.merged, otu, by = "SampleID")
hopsARS_all <- as.data.frame(hopsARS_all)

# select columns to be used in ml - SampleID, ECs, and "Overall" CASH rating
hopsARS_ml <- hopsARS_all[,c(1,95,152:2413)]

saveRDS(hopsARS_ml, "machine_learning/hopsARS_ml_EC.RDS")

### NRCS
# split NRCS data into two to keep R from crashing
func1 <- readRDS("../picrust2_files/NRCS/EC/pred_metagenome_contrib1.RDS")
func2 <- readRDS("../picrust2_files/NRCS/EC/pred_metagenome_contrib2.RDS")
df <- read.delim('../picrust2_files/NRCS/marker_predicted_and_nsti.tsv.gz', sep = '\t')

names(df) <- c("taxon", "genome_16S_count", "metadata_NSTI")

# combine two files
func1 <- func1 %>%
  full_join(df, by="taxon")
func2 <- func2 %>%
  full_join(df, by="taxon")

# add qPCR data to new func object
func1 <- merge(func1, qPCR_data, by = "sample")
func2 <- merge(func2, qPCR_data, by = "sample")

# we imported un-normalized counts, so normalizing here
func1$gene_counts <- func1$taxon_rel_abun / 100 * func1$genome_function_count / func1$genome_16S_count * func1$qPCR
func2$gene_counts <- func2$taxon_rel_abun / 100 * func2$genome_function_count / func2$genome_16S_count * func2$qPCR

# change column name "function" to "EC"
colnames(func1)[2] <- "EC"
colnames(func2)[2] <- "EC"

# pool data by sample and function
otu1 <- func1 %>%
  group_by(sample, EC) %>%
  summarize(sum=sum(gene_counts))
otu1 <- otu1 %>%
  spread(key=sample, value=sum)
otu1 <- data.frame(otu1)
otu1[is.na(otu1)] <- 0
row.names(otu1) <- otu1$EC
otu1 <- otu1[,-1]

otu2 <- func2 %>%
  group_by(sample, EC) %>%
  summarize(sum=sum(gene_counts))
otu2 <- otu2 %>%
  spread(key=sample, value=sum)
otu2 <- data.frame(otu2)
otu2[is.na(otu2)] <- 0
row.names(otu2) <- otu2$EC
otu2 <- otu2[,-1]

# transpose the "otu" table
otu1 <- t(otu1)
otu2 <- t(otu2)

# convert matrix to data frame
otu1 <- as.data.frame(otu1)
otu2 <- as.data.frame(otu2)

# make the sample names a column for merging later
otu1 <- tibble::rownames_to_column(otu1, "SampleID")
otu2 <- tibble::rownames_to_column(otu2, "SampleID")

# merge metadata and "otu" table
NRCS1 <- merge(data.merged, otu1, by = "SampleID")
NRCS1 <- as.data.frame(NRCS1)
NRCS2 <- merge(data.merged, otu2, by = "SampleID")
NRCS2 <- as.data.frame(NRCS2)

# select columns to be used in ml - SampleID, ECs, and "Overall" CASH rating
NRCS1_ml <- NRCS1[,c(1,95,152:2530)]
NRCS2_ml <- NRCS2[,c(1,95,152:2468)]

saveRDS(NRCS1_ml, "machine_learning/NRCS1_ml_EC.RDS")
saveRDS(NRCS2_ml, "machine_learning/NRCS2_ml_EC.RDS")

### Rangeland
# we don't need the full phyloseq from before, so reimporting
func <- read.delim('../picrust2_files/Rangeland/EC/pred_metagenome_contrib.tsv.gz', sep='\t')
df <- read.delim('../picrust2_files/Rangeland/marker_predicted_and_nsti.tsv.gz', sep = '\t')

names(df) <- c("taxon", "genome_16S_count", "metadata_NSTI")

# combine two files
func <- func %>%
  full_join(df, by="taxon")

# add qPCR data to new func object
func <- merge(func, qPCR_data, by = "sample")

# we imported un-normalized counts, so normalizing here
func$gene_counts <- func$taxon_rel_abun / 100 * func$genome_function_count / func$genome_16S_count * func$qPCR

# change column name "function" to "EC"
colnames(func)[2] <- "EC"

# pool data by sample and function
otu <- func %>%
  group_by(sample, EC) %>%
  summarize(sum=sum(gene_counts))
otu <- otu %>%
  spread(key=sample, value=sum)
otu <- data.frame(otu)
otu[is.na(otu)] <- 0
row.names(otu) <- otu$EC
otu <- otu[,-1]

# transpose the "otu" table
otu <- t(otu)

# convert matrix to data frame
otu <- as.data.frame(otu)

# make the sample names a column for merging later
otu <- tibble::rownames_to_column(otu, "SampleID")

# merge metadata and "otu" table
rangeland_all <- merge(data.merged, otu, by = "SampleID")
rangeland_all <- as.data.frame(rangeland_all)

# select columns to be used in ml - SampleID, ECs, and "Overall" CASH rating
rangeland_ml <- rangeland_all[,c(1,95,152:2391)]

saveRDS(rangeland_ml, "machine_learning/rangeland_ml_EC.RDS")

### final formatting of ml_all object

# merge ml dfs for Hops.2018 Hops.ARS, NRCS1, NRCS2, and Rangeland

ml_1 <- merge(hops2018_ml, hopsARS_ml, all = TRUE)
ml_2 <- merge(NRCS1_ml, ml_1, all = TRUE)
ml_3 <- merge(NRCS2_ml, ml_2, all = TRUE)
ml_all <- merge(rangeland_ml, ml_3, all = TRUE)

# going to assume that NAs are 0 (functions not found in one data set or another)
# change NAs to 0
ml_all[is.na(ml_all)] <- 0

# NRCS 346 duplicated for some reason. One row is all zeros. Get rid of row 316
ml_all <- ml_all[c(1:315,317:537),]

# make the sample names the row names again to make selecting columns for ml easy
rownames(ml_all) <- ml_all$SampleID

# get rid of sampleID column
ml_all <- ml_all[,c(2:2444)]

# check for any NAs in ml_all
sum(is.na(ml_all))
# none

# data is ready for ML

# save ML object
saveRDS(ml_all, "machine_learning/ml_all_EC.RDS")
```

### Machine learning of EC data to predict Overall CASH rating
# Without clay and climate, and just one train/test split with hyperparameter tuning
# Run in Ceres on Demand due to high computational requirements
# Don't need to run this again, skip this chunk (may delete later)
```{r}
# reload ML object
ml_all <- readRDS("/project/soil_micro_lab/micro_indicators/machine_learning/ml_all_EC.RDS")

set.seed(123456)

soil_split <- initial_split(ml_all, prop = 4/5)
soil_split
# 428 samples in training, 108 in testing, 536 total

# extract the train and test sets
soil_train <- training(soil_split)
soil_test <- testing(soil_split)

# cross validation
soil_cv <- vfold_cv(soil_train, v = 5, repeats = 10, strata = NULL)

# define a "recipe", i.e., the role of each variable in the model
# predicting overall CASH rating, and all other variables (ECs) are predictors
# if pre-processing steps or checks are needed (e.g., normalization), can use ?selections to see what selectors can be used

### might be able to just add clay/climate cols here and keep formula the same

soil_recipe <- recipe(Overall ~ ., data = ml_all)
soil_recipe
# 2442 predictors

# specify the model
# tune randomness, number of trees, and min nodes/max depth (# of splits each decision tree can make)
# trees = tune(), min_n = tune()
rf_model <- rand_forest() %>% 
  set_args(mtry = tune(), trees = tune(), min_n = tune()) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("regression")

# set the workflow
rf_workflow <- workflow() %>%
  add_recipe(soil_recipe) %>%
  add_model(rf_model)

# tune the parameters
# doing 25%, 50%, and 75% of the total number of predictors, respectively
rf_grid <- expand.grid(mtry = c(611,1223,1834),
                       trees = c(100,250,500),
                       min_n = c(3,5,7))

# extract results
rf_tune_results <- rf_workflow %>%
  tune_grid(resamples = soil_cv, grid = rf_grid, metrics = metric_set(mae, rmse))

# save tune results
saveRDS(rf_tune_results, "/project/soil_micro_lab/micro_indicators/machine_learning/ml_all_EC_tune_results.RDS")

rf_tune_results %>%
  collect_metrics()

# finalize the workflow
param_final <- rf_tune_results %>%
  select_best(metric = "mae")
param_final

rf_workflow <- rf_workflow %>%
  finalize_workflow(param_final)

# fit the model
# this will fit on the training set and evaluate on test set
rf_fit <- rf_workflow %>%
  last_fit(soil_split)
rf_fit

# save the fit
saveRDS(rf_fit, "/project/soil_micro_lab/micro_indicators/machine_learning/ml_all_EC_fit.RDS")

# see how well the model performs
test_performance <- rf_fit %>% collect_metrics()
test_performance

# generate predictions from the test set
test_predictions <- rf_fit %>% collect_predictions()
test_predictions

# graph a regression of predicted vs observed SH_rating values
CASH_EC_lm <- lm(Overall ~ .pred, data = test_predictions)
p1 <- ggplot(CASH_EC_lm$model, aes(x = Overall, y = .pred)) +
  geom_point() +
  stat_smooth(method = "lm", se = TRUE, level = 0.95) +
  labs(title = paste("Adj R2 =",signif(summary(CASH_EC_lm)$adj.r.squared, 2),
                     " P =",signif(summary(CASH_EC_lm)$coef[2,4], 2)),
                     x = "Observed CASH Rating", y = "Predicted CASH Rating") +
  theme_bw()
p1

# save plot
ggsave("/project/soil_micro_lab/micro_indicators/machine_learning/ml_all_EC_pred_vs_obs.tiff", unit = "in", width = 6, height = 6, 
       dpi = 300, device = "tiff")

# fitting the final model
# uses all data that can be tested on a new data set
final_model <- fit(rf_workflow, ml_all)

# save the final model
saveRDS(final_model, "/project/soil_micro_lab/micro_indicators/machine_learning/ml_all_EC_final_model.RDS")

# need to figure out what other data we can test this on, if anything
# code would look like this:
# predict(final_model, new_data = new_data_frame)

# variable importance
ranger_obj <- pull_workflow_fit(final_model)$fit
ranger_obj
var_importance <- as.data.frame(ranger_obj$variable.importance)
write.csv(var_importance, "/project/soil_micro_lab/micro_indicators/machine_learning/var_importance_EC.csv", row.names = TRUE)
```

### Machine learning of EC data to predict Overall CASH rating
# Trying to include clay and climate interactions in the model recipe
# Also includes hyperparameter tuning
# Run tuning, set model to optimal parameters, then run 25 times with different splits
# Save the output with labels 1-25, can compile R^2 values
# Run in Ceres on Demand due to high computational requirements
# For Dan - don't need scinet for troubleshooting, but if you can tune the grid (line 502) and it doesn't immediately error out, then I think the problem is solved. ml_all_EC.RDS and ml_all_cc.RDS (with clay/ClimateZ) are in the machine_learning folder in One Drive
# A lot of what I did came from here: https://www.rebeccabarter.com/blog/2020-03-25_machine_learning#tune-the-parameters
# Reference for adding dummy variables is here: https://recipes.tidymodels.org/reference/step_interact.html
```{r}
# reimport ml_all and add clay and climate back
# in hindsight it would've made more sense to keep clay and climate in ml_all and subset when I didn't need it
ml_all <- readRDS("/project/soil_micro_lab/micro_indicators/machine_learning/ml_all_EC.RDS")

# remake data.merged
data.pred.SHMI <- readRDS('/project/soil_micro_lab/micro_indicators/machine_learning/data.pred.SHMI.RDS')

# read in metadata that includes sampleIDs to merge with data.pred.SHMI
data.sampleID <- read.delim('/project/soil_micro_lab/micro_indicators/machine_learning/SHAI.Meta.22March2023.q2.reduced.txt', sep = '\t')

# merge metadata files
data.merged <- merge(data.pred.SHMI, data.sampleID, by = "PLFA_ID", all.x = TRUE)

# move the sample ID column to the front
data.merged <- data.merged %>% 
  relocate(SampleID)

# want to add climate zone columns and clay columns to ml_all
# subset data.merged to those columns + SampleID
data.merged2 <- data.merged[,c(1,71,103)]

# rownames to column in ml_all for merging
ml_all2 <- tibble::rownames_to_column(ml_all, "SampleID")

# merge ml_all2 with clay and climate
ml_all_cc <- merge(ml_all2, data.merged2, by = "SampleID")
rownames(ml_all_cc) <- ml_all_cc$SampleID
ml_all_cc <- ml_all_cc[,c(2:2446)]
ml_all_cc <- ml_all_cc %>% 
  relocate(clay, .before = Overall) %>% 
  relocate(ClimateZ, .before = Overall)

# ml_all_cc ready for ml

# do not set seed so splits are random each time - want 25 different splits

soil_split <- initial_split(ml_all_cc, prop = 4/5)
soil_split
# 428 samples in training, 108 in testing, 536 total

# extract the train and test sets
soil_train <- training(soil_split)
soil_test <- testing(soil_split)

# cross validation
soil_cv <- vfold_cv(soil_train, v = 5, repeats = 10, strata = NULL)

# define a "recipe", i.e., the role of each variable in the model
# predicting overall CASH rating, including clay and ClimateZ interactions, and all other variables (ECs) are predictors
# if pre-processing steps or checks are needed (e.g., normalization), can use ?selections to see what selectors can be used

soil_recipe <- recipe(Overall ~ ., data = ml_all_cc) %>% 
  step_dummy(all_nominal()) %>% 
#  step_normalize(all_numeric()) %>% 
  step_interact(terms = ~ clay:select(starts_with("ClimateZ")))
soil_recipe
# 2444 predictors

# specify the model
# tune randomness, number of trees, and min nodes/max depth (# of splits each decision tree can make)
# trees = tune(), min_n = tune()
rf_model <- rand_forest() %>% 
  set_args(mtry = tune(), trees = tune(), min_n = tune()) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("regression")

# set the workflow
rf_workflow <- workflow() %>%
  add_recipe(soil_recipe) %>%
  add_model(rf_model)

# tune the parameters
# doing 25%, 50%, and 75% of the total number of predictors, respectively
rf_grid <- expand.grid(mtry = c(611,1222,1833),
                       trees = c(100,250,500),
                       min_n = c(3,5,7))

# extract results
rf_tune_results <- rf_workflow %>%
  tune_grid(resamples = soil_cv, grid = rf_grid, metrics = metric_set(mae, rmse))
######## if the code directly above doesn't error out, should be good. If it does work, it will take many hours
### Also tried bringing in the 0/1 columns for each climate zone into the recipe and couldn't get that to work

# save tune results
saveRDS(rf_tune_results, "/project/soil_micro_lab/micro_indicators/machine_learning/ml_all_EC_tune_results.RDS")

rf_tune_results %>%
  collect_metrics()

# finalize the workflow
param_final <- rf_tune_results %>%
  select_best(metric = "mae")
param_final

rf_workflow <- rf_workflow %>%
  finalize_workflow(param_final)

# fit the model
# this will fit on the training set and evaluate on test set
rf_fit <- rf_workflow %>%
  last_fit(soil_split)
rf_fit

# save the fit
saveRDS(rf_fit, "/project/soil_micro_lab/micro_indicators/machine_learning/ml_all_EC_fit.RDS")

# see how well the model performs
test_performance <- rf_fit %>% collect_metrics()
test_performance

# generate predictions from the test set
test_predictions <- rf_fit %>% collect_predictions()
test_predictions

# graph a regression of predicted vs observed SH_rating values
CASH_EC_lm <- lm(Overall ~ .pred, data = test_predictions)
p1 <- ggplot(CASH_EC_lm$model, aes(x = Overall, y = .pred)) +
  geom_point() +
  stat_smooth(method = "lm", se = TRUE, level = 0.95) +
  labs(title = paste("Adj R2 =",signif(summary(CASH_EC_lm)$adj.r.squared, 2),
                     " P =",signif(summary(CASH_EC_lm)$coef[2,4], 2)),
                     x = "Observed CASH Rating", y = "Predicted CASH Rating") +
  theme_bw()
p1

# save plot
ggsave("/project/soil_micro_lab/micro_indicators/machine_learning/ml_all_EC_pred_vs_obs.tiff", unit = "in", width = 6, height = 6, 
       dpi = 300, device = "tiff")

# fitting the final model
# uses all data that can be tested on a new data set
final_model <- fit(rf_workflow, ml_all)

# save the final model
saveRDS(final_model, "/project/soil_micro_lab/micro_indicators/machine_learning/ml_all_EC_final_model.RDS")

# need to figure out what other data we can test this on, if anything
# code would look like this:
# predict(final_model, new_data = new_data_frame)

# variable importance
ranger_obj <- pull_workflow_fit(final_model)$fit
ranger_obj
var_importance <- as.data.frame(ranger_obj$variable.importance)
write.csv(var_importance, "/project/soil_micro_lab/micro_indicators/machine_learning/var_importance_EC.csv", row.names = TRUE)


```





